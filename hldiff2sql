#!/usr/bin/env python3

import argparse
import sys
import csv


def readrows(file):
    r = csv.reader(file)
    header = next(r)
    return list(r), header


def build_insert_sql(table, cols):
    return 'insert into {table} ({cols}) values ({values})'.format(
        table=table,
        cols=', '.join(cols),
        values=', '.join(['?'] * len(cols))
    )


def filter_inserted_rows(rows):
    return [row[1:] for row in filter(lambda r: r[0] == '+++', rows)]


def build_delete_sql(table, cols):
    return 'delete from {table} where {filters}'.format(
        table=table,
        filters=' and '.join([c + ' = ?' for c in cols])
    )


def filter_deleted_rows(rows):
    return [row[1:] for row in filter(lambda r: r[0] == '---', rows)]


def build_update_sql(table, cols, updated_cols):
    return 'update {table} set {setters} where {filters}'.format(
        table=table,
        setters=', '.join([c + ' = ?' for c in updated_cols]),
        filters=' and '.join([c + ' = ?' for c in cols])
    )


def filter_updated_rows(rows):
    return filter(lambda r: r[0].endswith('->'), rows)
    

def get_updates(rows):
    updates = []
    for row in rows:
        tag = row[0]
        updated_cols = []
        new_vals = []
        orig_row = []
        for col, val in enumerate(row[1:]):
            if tag in val:
                updated_cols.append(col)
                old, new = val.split(tag)
                orig_row.append(old)
                new_vals.append(new)
            else:
                orig_row.append(val)

        updates.append((updated_cols, new_vals, orig_row))
        
    return updates


def writerows(file, rows):
    csv.writer(file, delimiter='\t').writerows(rows)


def main(table):
    rows, cols = readrows(sys.stdin)
    cols = cols[1:] # remove action column from header

    inserted_rows = filter_inserted_rows(rows)
    if inserted_rows:
        sql = build_insert_sql(table, cols)
        print(sql)
        writerows(sys.stdout, [cols] + inserted_rows)

    deleted_rows = filter_deleted_rows(rows)
    if deleted_rows:
        sql = build_delete_sql(table, cols)
        print(sql)
        writerows(sys.stdout, [cols] + deleted_rows)


    updated_rows = filter_updated_rows(rows)
    if updated_rows:
        updates = get_updates(updated_rows)
        for updated_col_indices, new_vals, orig_row in updates:
            updated_cols = [cols[i] for i in updated_col_indices]
            sql = build_update_sql(table, cols, updated_cols)
            print(sql)
            writerows(
                sys.stdout,
                [updated_cols + cols] + [new_vals + orig_row]
            )


def setup():
    # Redefine stdin to not translate newlines. Otherwise when reading
    # csv field containing \r\n on Windows it gets translated to \n,
    # i.e. data gets corrupted. Always use utf-8.
    sys.stdin = open(
        sys.stdin.fileno(),
        mode=sys.stdin.mode,
        encoding='utf-8',
        errors=sys.stdin.errors,
        newline='',
        closefd=False
    )
    # Redefine stdout to not translate newlines. csv module (as per
    # rfc 4180) writes \r\n. Otherwise when on Windows, \n is
    # translated to \r\n, so original \r\n becomes \r\r\n. Always use
    # utf-8.
    sys.stdout = open(
        sys.stdout.fileno(),
        mode=sys.stdout.mode,
        encoding='utf-8',
        errors=sys.stdout.errors,
        newline='',
        closefd=False
    )


def parse_args():
    p = argparse.ArgumentParser(
        description='Convert highlighter diff to sql instructions to patch the table'
    )
    p.add_argument(
        'table',
        help='target table'
    )
    return p.parse_args()


if __name__ == '__main__':
    args = parse_args()
    setup()
    main(args.table)
