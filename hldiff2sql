#!/usr/bin/env python3

import argparse
import sys
import csv


class Error(Exception):

    def __init__(self, *args):
        super().__init__(*args)


def read_diff(file):
    r = csv.reader(file)
    try:
        header = next(r)
    except StopIteration:
        return [], []

    # break on schema changes
    if header[0] == '!':
        raise Error('NotSupported: input diff contains schema row, but schema changes are not supported')

    return list(r), header


def gen_insert_sql(table, cols):
    return 'insert into {table} ({cols}) values ({values})'.format(
        table=table,
        cols=', '.join(cols),
        values=', '.join(['?'] * len(cols))
    )


def gen_insert_chunks(table, diffrows, colnames, col_defs):
    inserted_rows = [
        row[1:]
        for row in filter(lambda r: r[0] == '+++', diffrows)
    ]
    if inserted_rows:
        return [
            [[gen_insert_sql(table, colnames)]] +
            [col_defs] + 
            inserted_rows
        ]
    return []


def gen_delete_sql(table, cols):
    return 'delete from {table} where {filters}'.format(
        table=table,
        filters=' and '.join([c + ' = ?' for c in cols])
    )


def gen_delete_chunks(table, diffrows, colnames, col_defs):
    deleted_rows = [
        row[1:]
        for row in filter(lambda r: r[0] == '---', diffrows)
    ]
    if deleted_rows:
        return [
            [[gen_delete_sql(table, colnames)]] +
            [col_defs] +
            deleted_rows
        ]
    return []


def gen_update_sql(table, cols, updated_cols):
    return 'update {table} set {setters} where {filters}'.format(
        table=table,
        setters=', '.join([c + ' = ?' for c in updated_cols]),
        filters=' and '.join([c + ' = ?' for c in cols])
    )


def get_update_items(updated_rows):
    items = []
    for row in updated_rows:
        tag = row[0]
        updated_cols = []
        new_vals = []
        orig_row = []
        for col, val in enumerate(row[1:]):
            if tag in val:
                updated_cols.append(col)
                old, new = val.split(tag)
                orig_row.append(old)
                new_vals.append(new)
            else:
                orig_row.append(val)

        items.append((updated_cols, new_vals, orig_row))
        
    return items


def gen_update_chunks(table, diffrows, colnames, col_defs):
    updated_rows = filter(lambda r: r[0].endswith('->'), diffrows)
    items = get_update_items(updated_rows)
    updates = []
    for updated_col_indices, new_vals, orig_row in items:
        updated_colnames = [colnames[i] for i in updated_col_indices]
        updated_col_defs = [col_defs[i] for i in updated_col_indices]
        updates.append([
            [gen_update_sql(table, colnames, updated_colnames)],
            updated_col_defs + col_defs,
            new_vals + orig_row
        ])
    return updates


def insert_between(value, lst):
    """Return list where value is inserted between every two items of lst."""
    return sum([[x, value] for x in lst[:-1]], []) + lst[-1:]


def writerows(file, rows):
    csv.writer(file, delimiter='\t').writerows(rows)


def main(table, typed_header=False):
    diffrows, col_defs = read_diff(sys.stdin)
    col_defs = col_defs[1:] # remove action column

    colnames = col_defs
    if typed_header:
        colnames = [c.split(' ')[0] for c in col_defs]

    chunks = (
        gen_insert_chunks(table, diffrows, colnames, col_defs) +
        gen_delete_chunks(table, diffrows, colnames, col_defs) +
        gen_update_chunks(table, diffrows, colnames, col_defs)
    )
    # insert empty rows between chunks, they will be output as empty
    # line separators
    chunks = insert_between([[]], chunks)
    # concatenate chunks to produce list of rows
    out_rows = sum(chunks, [])
    writerows(sys.stdout, out_rows)    


def setup():
    # Redefine stdin to not translate newlines. Otherwise when reading
    # csv field containing \r\n on Windows it gets translated to \n,
    # i.e. data gets corrupted. Always use utf-8.
    sys.stdin = open(
        sys.stdin.fileno(),
        mode=sys.stdin.mode,
        encoding='utf-8',
        errors=sys.stdin.errors,
        newline='',
        closefd=False
    )
    # Redefine stdout to not translate newlines. csv module (as per
    # rfc 4180) writes \r\n. Otherwise when on Windows, \n is
    # translated to \r\n, so original \r\n becomes \r\r\n. Always use
    # utf-8.
    sys.stdout = open(
        sys.stdout.fileno(),
        mode=sys.stdout.mode,
        encoding='utf-8',
        errors=sys.stdout.errors,
        newline='',
        closefd=False
    )


def parse_args():
    p = argparse.ArgumentParser(
        description='Convert highlighter diff to sql instructions to patch the table'
    )
    p.add_argument(
        '-typed-header',
        action='store_true',
        help='input has typed header. Column type is separated from column name by space'
    )
    p.add_argument(
        'table',
        help='target table'
    )
    return p.parse_args()


if __name__ == '__main__':
    args = parse_args()
    setup()
    main(
        args.table,
        typed_header=args.typed_header
    )
